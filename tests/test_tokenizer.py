import tiktoken
from embedia.tokenizer import Tokenizer
import pytest


class GPTTokenizer(Tokenizer):
    def __init__(self):
        self.enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
        # self.enc = tiktoken.encoding_for_model("gpt-4")
        # self.enc = tiktoken.get_encoding("cl100k_base")
        # text-davinci-003 uses p50k_base

    async def _tokenize(self, text):
        return self.enc.encode(text)


text = """Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu arcu risus. Proin sed fringilla tellus. Donec scelerisque elit sed sapien bibendum rutrum. Morbi blandit justo in urna semper volutpat. Nunc consectetur ex vitae consequat blandit. Duis sit amet metus quis mi molestie bibendum rutrum et ante. Nam aliquam metus magna, eget porta lacus dictum sit amet. Morbi dictum tellus a semper tristique. Duis ipsum ex, pharetra non rhoncus in, gravida quis magna. Nam pretium enim non lectus efficitur, sit amet sagittis elit finibus. Vivamus varius ligula turpis, sit amet vehicula mi eleifend eget. Cras dignissim mauris eu feugiat euismod. Integer dapibus dolor eu nulla euismod finibus."""


@pytest.mark.asyncio
async def test_tokenizer():
    tokenizer = GPTTokenizer()
    tokens = await tokenizer(text)
    assert len(text.split()) == 107
    assert len(tokens) == 192
    print(tokens)
